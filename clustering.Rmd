---
author: J-P Gattuso, J-O Irisson
output: 
  html_document: 
    css: document.css
---

# Clustering of CC mitigation solutions

*J-P Gattuso, J-O Irisson  
`r Sys.Date()`*


```{r prep, echo=FALSE, message= FALSE}
knitr::opts_chunk$set(
  echo=F,
  comment="",
  cache=T
)
library("tidyverse")
library("stringr")
library("FactoMineR")
library("broom")
library("ggplot2")
library("ggrepel")
library("dendextend")
# devtools::install_github("jiho/chroma")
library("chroma")
```


## Data 

```{r read_data}
## Global effects
t1a <- read_csv(file="table_1a.csv", col_types=cols()) %>% 
        rename(`Alkalinization (g)`=Alkalinization, `Vegetation (g)`=Vegetation)

t1b <- read_csv(file="table_1b.csv", col_types=cols()) %>% 
        rename(`Alkalinization (l)`=Alkalinization, `Vegetation (l)`=Vegetation, `Relocation, Restoration`=Relocation_Restoration)
# score relative and absolute sea level rise together
t1b$Criteria <- str_replace(t1b$Criteria, "Moderate relative sea", "Moderate sea")

t1 <- full_join(t1a, t1b, by="Criteria")

t1$Criteria <- t1$Criteria %>% 
  # abbreviate some words for clarity of plots
  str_replace("until full potential effectiveness", "until full pot. effectiv.") %>% 
  # force order
  factor(levels=unique(.))


## Local effects
t3 <- read_csv(file="table_3.csv", col_types=cols()) 
# make names clearer
t3 <- t3 %>% rename(`Relocation, Restoration`=Relocation_Restoration)
names(t3) <- str_replace(names(t3), "_g", " (g)")
names(t3) <- str_replace(names(t3), "_l", " (l)")
t3$Criteria <- t3$Criteria %>% 
  # make labels clearer
  str_replace("_", " ") %>% 
  str_replace("Warming", "Reduce impact of warming") %>% 
  str_replace("Acidification", "Reduce impact of acidification") %>% 
  str_replace("Sea level rise", "Reduce impact of sea level rise") %>% 
  str_replace("Other drivers", "Reduce impacts of other drivers") %>% 
  # force order
  factor(levels=unique(.))

# keep everything
t3a <- t3 %>%
        mutate(Criteria=str_c(Category, Criteria, sep="_")) %>%
        select(-Category)
# summarise per criterion, across ecosystems
t3c <- t3 %>% select(-Category) %>% group_by(Criteria) %>% summarise_all(mean, na.rm=T)
# summarise per ecosystem, across criteria
t3e <- t3 %>% select(-Criteria) %>% group_by(Category) %>% summarise_all(mean, na.rm=T)


dt <- suppressWarnings(bind_rows(t1, t3a)) %>% gather(key="Solutions", value="Score", -Criteria)
dw <- dt %>% spread(key="Criteria", value="Score") %>% as.data.frame()

dst <- suppressWarnings(bind_rows(t1, t3c)) %>% gather(key="Solutions", value="Score", -Criteria)
# force order of factors
dst$Solutions <- factor(dst$Solutions)                            # alphabetical
dst$Criteria <- factor(dst$Criteria, levels=unique(dst$Criteria)) # current order
dsw <- dst %>% spread(key="Criteria", value="Score") %>% as.data.frame()
```

The data consists of `r ncol(t1)-1` climate-change mitigation solutions

```{r}
levels(dst$Solutions)
```

Each is scored from 1 (sometimes 0) to 5 according to `r nlevels(t1$Criteria)` global criteria

```{r}
levels(t1$Criteria)
```

As well as `r nlevels(t3$Criteria)` local criteria

```{r}
levels(t3$Criteria)
```
evaluated in in `r length(unique(t3$Category))` "ecosystems"

```{r}
sort(unique(t3$Category))
```

For simplicity and/or the requirements of the techniques, the *scores* for these local criteria are often *averaged* across ecosystems.

## Plot of relationships

### Circle (Chord) diagrams

Fig x: Links between solutions (light gray) and scoring criteria, either global (black) or local (grey). The links are coloured according to the score, from red (bad) to good (green; grey is an undefined score). For each solution, links are ordered by increasing score.

```{r circos, fig.height=9, fig.width=9}
library("circlize")

# prepare data for Chord diagram
d <- dst %>%
  mutate(
    # add a column of ones for the line width
    One=1,
    # replace empty scores
    Score0=replace(Score, is.na(Score), 0),
    # compute colors manually
    # Color=ifelse(is.na(Score), "grey", brewer_map(Score0, name="RdYlGn")) # red=0, green=5; alternatives RdYlBu (PRGn) and YlGnBu
    Color=ifelse(is.na(Score), "grey", viridis_map(Score0, rev=FALSE)) # or viridis_map; can use reverse=TRUE
  ) %>%
  # to get the rage of colors 0 to 5: show_col(viridis_colors(100, rev=F))
  # sort by Score within each solution
  arrange(Solutions, desc(Score)) %>%
  # reorder columns for chordDiagram
  select(Criteria, Solutions, One, 1:ncol(.)) %>% 
  as.data.frame()

# shorten label
levels(d$Criteria) <- str_wrap(levels(d$Criteria), width=16)
levels(d$Solutions) <- str_wrap(levels(d$Solutions), width=16)

chordDiagram(d,
  # map precomputed color to lines
  col=d$Color,
  order=c(levels(d$Criteria), levels(d$Solutions)),
  # color grid according to type of data: global criterion, local criterion, solution
  grid.col=rep(
    c("grey0", "grey40", "grey80"),
    times=c(nlevels(t1$Criteria), nlevels(t3$Criteria), nlevels(d$Solutions))
  ),
  # remove axis around plot
  annotationTrack=c("name", "grid"),
  # put green lines one top
  link.largest.ontop=TRUE,
  # plot aspect
  h.ratio=0.6, transparency=0.1,
  directional=1, direction.type="diffHeight"
)

d_drivers <- filter(d, Criteria %in% levels(d$Criteria)[1:3]) # only the 3 drivers
chordDiagram(d_drivers,
  # map precomputed color to lines
  col=d$Color,
  order=c(levels(d$Criteria), levels(d$Solutions)),
  # color grid according to type of data: criterion or solution
  grid.col=rep(
    c("grey0", "grey80"),
    times=c(3, nlevels(d$Solutions))
  ),
  # remove axis around plot
  annotationTrack=c("name", "grid"),
  # put green lines one top
  link.largest.ontop=TRUE,
  # plot aspect
  h.ratio=0.6, transparency=0.1,
  directional=1, direction.type="diffHeight"
)

d_criteria <- filter(d, Criteria %in% levels(d$Criteria)[4:13]) # the other ones
chordDiagram(d_criteria,
  # map precomputed color to lines
  col=d$Color,
  order=c(levels(d$Criteria), levels(d$Solutions)),
  # color grid according to type of data: criterion or solution
  grid.col=rep(
    c("grey0", "grey80"),
    times=c(10, nlevels(d$Solutions))
  ),
  # remove axis around plot
  annotationTrack=c("name", "grid"),
  # put green lines one top
  link.largest.ontop=TRUE,
  # plot aspect
  h.ratio=0.6, transparency=0.1,
  directional=1, direction.type="diffHeight"
)

```

### Alluvial diagram

Fig x: Same legend as above. Boxes should be drawn around solutions and criteria to better define them

```{r alluvial, fig.height=9, warning=FALSE}
library("alluvial")

alluvial(
  # draw lines, ordered by score in each solution
  d[,2:1], freq=1,
  ordering=list(with(d, order(Solutions, Score)), NULL),
  # map color
  col=d$Color,
  # cleaner aspect
  border=NA, alpha=0.9, xw=0.2, cw=0.12, blocks=F, gap.width=0.15, cex=0.8
)

alluvial(
  # draw lines, ordered by score in each solution
  d_drivers[,2:1], freq=1,
  ordering=list(with(d_drivers, order(Solutions, Score)), NULL),
  # map color
  col=d_drivers$Color,
  # cleaner aspect
  border=NA, alpha=0.9, xw=0.2, cw=0.12, blocks=F, gap.width=0.15, cex=0.8,
  axis_labels=c("Solutions", "Global\ncriteria")
)

alluvial(
  # draw lines, ordered by score in each solution
  d_criteria[,2:1], freq=1,
  ordering=list(with(d_criteria, order(Solutions, Score)), NULL),
  # map color
  col=d_criteria$Color,
  # cleaner aspect
  border=NA, alpha=0.9, xw=0.2, cw=0.12, blocks=F, gap.width=0.15, cex=0.8,
  axis_labels=c("Solutions", "Local\ncriteria")
)
```

### Custom line plot

```{r butterfly, fig.height=7, fig.width=10}
# compute effectiveness to reduce CC
d_effect <- t3 %>%
  gather(key="Solutions", value="Score", -Category, -Criteria) %>%
  # remove cobenefits and lack of unintended => focus on effectiveness to reduce CC effects
  filter(str_detect(Criteria, "Reduce")) %>%
  # average effectiveness scores
  group_by(Category, Solutions) %>%
  summarise(effect=mean(Score, na.rm=T)) %>% 
  ungroup()

# separate ecosystem vs ecosystem services
d_effect$Cat_type <- ifelse(d_effect$Category %in% c("Arctic biota", "Coral reefs", "Mangroves and saltmarshes", "Seagrass habitats"), "ecosystem", "ecosystem services")

# separate solutions based on their scope
d_effect$Sol_type <- ifelse(d_effect$Solutions %in% c("Albedo enhancement", "Alkalinization (g)", "Cloud brightening", "Hybrids", "Fertilization", "Renewable energy", "Vegetation (g)"), "global", "local")

# compute global feasability per solution
d_feas <- dst %>% 
  # focus on feasability
  filter(Criteria %in% c("Technological readiness", "Lead time until full pot. effectiv.")) %>% 
  # average scores
  group_by(Solutions) %>%
  summarise(feas=mean(Score, na.rm=T))


# Plot:
# place solutions on a circle around the outside of the plot (separating local solutions on the left and global solutions on the right)
# place the ecosystem/ecosystem services on the inside
# draw curves from solutions to the center, coloured according to 

# compute coodinates of solutions along a circle
free_space <- pi/6
radius <- 20

d_out_l <- d_effect %>% filter(Sol_type=="local") %>% select(Sol_type, Solutions) %>% unique() %>% 
  mutate(a=seq(pi/2 + free_space, 3*pi/2 - free_space, length.out=length(unique(Solutions))))
d_out_g <- d_effect %>% filter(Sol_type=="global") %>% select(Sol_type, Solutions) %>% unique() %>% 
  mutate(a=seq(pi/2 - free_space, -pi/2 + free_space, length.out=length(unique(Solutions))))
d_out <- bind_rows(d_out_l, d_out_g)
d_out$x <- radius * cos(d_out$a)
d_out$y <- radius * sin(d_out$a)

# add feasbility
d_out <- left_join(d_out, d_feas, by = "Solutions")

# store coordinates in general data.frame
d_effect <- left_join(d_effect, d_out, by = c("Solutions", "Sol_type"))


# compute coordinates of categories in the center
d_in <- d_effect %>% select(Cat_type, Category) %>% unique() %>% group_by(Cat_type) %>%
  mutate(yc=scale(as.numeric(factor(Category)))*radius/3)
# store coordinates in general data.frame
d_effect <- left_join(d_effect, d_in, by = c("Category", "Cat_type"))
d_effect$xc <- ifelse(d_effect$Sol_type == "global", radius/6, -radius/6)

# curvature should change along the vertical position
d_effect$curv <- d_effect$y / 50
d_effect$curv <- ifelse(d_effect$Sol_type == "global", -d_effect$curv, d_effect$curv)

# geom_curve does not allow to change the curvature so we plot each curve separately (not very elegant but works...)
curves <- function(x, y, xend, yend, curvature, colour, ...) {
  df <- data.frame(x, y, xend, yend, curvature, colour)
  plyr::alply(df, 1, function(x) {
    geom_curve(aes(x, y, xend=xend, yend=yend, colour=colour), data=x, curvature=round(x$curvature, 2), ...)
  })
}

# ecosystems
ggplot() + coord_fixed() + scale_x_continuous(expand=c(0,7)) + theme_void() +
  # joining lines
  with(filter(d_effect, Cat_type=="ecosystem"), curves(x=x, y=y, xend=xc, yend=yc, curvature=curv, colour=effect, alpha=0.85, size=2, ncp=7, lineend="round")) +
  # solutions
  geom_point(aes(x, y, size=feas), data=d_out) +
  geom_text(aes(x*1.05, y*1.05, label=str_wrap(Solutions, 17)), hjust="outward", vjust="outward", d_out) +
  # ecosystems/ecosystem services
  geom_text(aes(x=0, y=yc, label=str_wrap(Category, 15)), filter(d_in, Cat_type=="ecosystem")) +
  # niceties
  scale_color_gradientn("Combined\neffectiv.", colours=viridis_colors(6), limits=c(1,5)) +
  scale_size_area("Overall\nfeasability", max_size=10, limits=c(1,5))
ggsave("fig_butterfly_1.pdf")

# ecosystem services
ggplot() + coord_fixed() + scale_x_continuous(expand=c(0,7)) + theme_void() +
  # joining lines
  with(filter(d_effect, Cat_type=="ecosystem services"), curves(x=x, y=y, xend=xc, yend=yc, curvature=curv, colour=effect, alpha=0.85, size=2, ncp=7, lineend="round")) +
  # solutions
  geom_point(aes(x, y, size=feas), data=d_out) +
  geom_text(aes(x*1.05, y*1.05, label=str_wrap(Solutions, 17)), hjust="outward", vjust="outward", d_out) +
  # ecosystems/ecosystem services
  geom_text(aes(x=0, y=yc, label=str_wrap(Category, 15)), filter(d_in, Cat_type=="ecosystem services")) +
  # niceties
  scale_color_gradientn("Combined\neffectiv.", colours=viridis_colors(6), limits=c(1,5)) +
  scale_size_area("Overall\nfeasability", max_size=10, limits=c(1,5))
ggsave("fig_butterfly_2.pdf")
```




### Scatter plot

```{r scatterplot}
d_effect <- dst %>% filter(str_detect(Criteria, "Moderate") | str_detect(Criteria, "Reduce")) %>% group_by(Solutions) %>% summarise(`Combined effectiveness`=mean(Score, na.rm=T))
d_feas <- dst %>% filter(Criteria %in% c("Technological readiness", "Lead time until full pot. effectiv.")) %>% group_by(Solutions) %>% summarise(`Overall feasability`=mean(Score, na.rm=T))
dss <- full_join(d_effect, d_feas, by = "Solutions")

ggplot(dss, aes(x=`Combined effectiveness`, y=`Overall feasability`, label=Solutions)) + geom_point() + geom_text_repel() + coord_fixed() + xlim(1,5) + ylim(1,5)
```

### Checker board

```{r checkboard, warning=F}
dd <- dst
dd$category <- ifelse(dd$Criteria %in% levels(dst$Criteria)[1:8], "global", "local")
dss$category <- "aggregate"
dsst <- gather(dss, key=Criteria, value=Score, -Solutions, -category)
dd <- bind_rows(dd, dsst)

# reset factor levels
dd$Criteria <- factor(dd$Criteria, levels=c(unique(dsst$Criteria), levels(dst$Criteria)))

ggplot(dd) + geom_raster(aes(x=Criteria, y=Solutions, fill=Score)) + scale_fill_gradientn(colours=viridis_colors(6)) + coord_fixed() + theme(axis.text.x=element_text(angle=45, hjust=1)) + scale_x_discrete(expand=c(0,0)) + scale_y_discrete(expand=c(0,0)) + facet_grid(.~category, scales="free_x", shrink=F, space="free_x")
```


## Clustering

Clustering the full, non-aggregated data set, with hierarchical clustering (Euclidean distance, Ward aggregation method to highlight synthetic groups) suggests three groups:

```{r hclust}
# reformat data for clustering
d <- dw
row.names(d) <- d$Solutions
d <- select(d, -Solutions)
hc <- as.dendrogram(hclust(dist(d), method="ward.D2"))

# cut tree
n <- 3 # based on the genral aspect of the plot

# nice plot
pars <- par(no.readonly=T)
par(mai=c(2,0.5,0.1,0.1))
# cols <- hue_colors(n)
cols <- brewer_colors(3, name = "Dark2")[c(2,1,3)] # keep order compared to hue colors
hc <- color_labels(hc, k=n, col=cols)
hc <- color_branches(hc, k=n, col=cols)
plot(hc)
par(pars)
```

The same technique for the dataset in which the scores are averaged by ecosystem gives mostly the same grouping

```{r hclust_s}
# reformat data for clustering
d <- dsw
row.names(d) <- d$Solutions
d <- select(d, -Solutions)
hc <- as.dendrogram(hclust(dist(d), method="ward.D2"))

# cut tree
n <- 3 # based on the general aspect of the plot

# nice plot
pars <- par(no.readonly=T)
par(mai=c(2,0.5,0.1,0.1))
# cols <- hue_colors(n)
cols <- brewer_colors(3, name = "Dark2")[c(2,1,3)]
hc <- color_labels(hc, k=n, col=cols)
hc <- color_branches(hc, k=n, col=cols)
plot(hc)
par(pars)
```

The distribution of scores for each criterion in the clusters (computed from the averaged dataset) are

```{r scores, fig.height=10}
# associate groups with the correct solution, preserving the colors compared to the previous plots
groups <- data.frame(
  Solutions=factor(labels(hc)),
  colour=unlist(dendrapply(hc, function(x) {attributes(x)$nodePar$lab.col}))
)
dsg <- left_join(dst, groups, by="Solutions")

# plot
levels(dsg$Criteria) <- str_wrap(levels(dsg$Criteria), 15)
ggplot(dsg) + geom_violin(aes(x=Criteria, y=Score, fill=colour), scale="width", colour=alpha("black", 0.5), na.rm=T) + scale_fill_identity() + coord_flip() + geom_vline(aes(xintercept=8.5))
```

This plot can be read as:

- the green solutions are particularly effective (high scores) against warming, both local and global. They also tend to be more effective against acidification. They are quite ineffective against other drivers and have low scores for global governability, cost effectiveness and co-benefits.
- the red solutions are practical: high readiness, good governability, few unintended effects, and high co-benefits; however they are not very effective against warming and acidification
- the purple solutions are mostly average everywhere, except they have somewhat good cost effectiveness, low co-benefits, and are not very effective to moderate acidification globally.


## PCA then clustering

A principal component analysis (PCA) can be used to examine the most important correlations and remove noise before the clustering step.

The PCA is performed without scaling the data, assuming that all criteria have equal importance and that those for which the solutions are all scored similarly are not discriminative and should not matter much. For simplicity, we use the scores averaged by ecosystem.

The eigenvalues or the PCA highlights that the first 4 PCs hold significant information

```{r PCA}
# reformat data for PCA
d <- dsw
row.names(d) <- d$Solutions
d <- select(d, -Solutions)

# cleanup labels
names(d) <- str_wrap(names(d), 18)

# perform PCA without scaling (since most variables are in the same range)
pca <- suppressWarnings(PCA(d, graph=F, scale=F))

# inspect eigenvalue
qplot(1:nrow(pca$eig), pca$eig$eigenvalue) + geom_hline(yintercept=mean(pca$eig$eigenvalue), colour="red")
```

Hierarchical clustering (Euclidean distance, Ward aggregation method) is performed on the coordinates of the solutions on those first 4 PCs. As before, 3 groups seem to emerge and are mostly equivalent to those highlighted on the raw data (which is expected of course, since the PCA just summarises the data and removes noise...).

```{r clust_on_PCA}
# perform synthetic clustering
coords <- pca$ind$coord[,1:4]
hc_pca <- as.dendrogram(hclust(dist(coords), method="ward.D2"))

# cut tree
n <- 3 # based on the genral aspect of the plot

# nice plot
pars <- par(no.readonly=T)
par(mai=c(2,0.5,0.1,0.1))
# cols <- hue_colors(n)
cols <- brewer_colors(3, name = "Dark2")[c(2,1,3)]
hc_pca <- color_labels(hc_pca, k=n, col=cols)
hc_pca <- color_branches(hc_pca, k=n, col=cols)
plot(hc_pca)
par(pars)
```

The real interest here is that the clusters can re-projected in the PCA space where the solutions can be individually related to the criteria in which they score well. The two following plots represent:

1. the correlation of criteria based on their scoring, which define the PCA space. The angle between the lines of the criteria reflect their correlation: two lines close to each other means that most solutions have similar scores for these two criteria, two lines at 90ยบ angle means that solutions have scores that are completely uncorrelated for these two criteria.
2. the solutions distributed in the PCA space space according to their scoring patterns and clustered into groups of solutions with similar scoring patterns. If a solution is in the general direction in which a criterion points, it has a high score according to this criterion (and if it is in the opposite direction, it has a low score).

In both cases, the criteria or solutions which are not well represented in this PCA space (i.e. which have quite nondescript scoring patterns) are made semi-transparent.

```{r PCA_and_clust, fig.height=5, fig.width=6}
# plot result of PCA and clustering together


#' Extract data from a PCA object
#'
#' @param x output of FactoMineR::PCA
#' @param data original data; optional
#' @param dimensions PCs to extract
#' @param which objects/rows/individuals or descriptors/columns/variables
augment.PCA <- function(x, data=NULL, dimensions=c(1,2), which=c("ind", "var")) {
  which <- match.arg(which)
  d <- data.frame(
    x[[which]]$coord[,dimensions],
    cos2=rowSums(x[[which]]$cos2[,dimensions]),
    contrib=rowSums(x[[which]]$contrib[,dimensions])
  )
  d$label <- row.names(d)
  if (which == "ind" & !is.null(data)) {
    d <- cbind(d, data)
  }
  return(d)
}

# define groups of solutions from clustering, preserving the colors compared to the dendrogram plot
groups <- data.frame(
  label=labels(hc_pca),
  colour=unlist(dendrapply(hc_pca, function(x) {attributes(x)$nodePar$lab.col}))
)

# extract objects from PCA
pca_i12 <- augment(pca)
# add clusters
pca_i12 <- left_join(pca_i12, groups, by = "label")
# extract variables from PCA
pca_v12 <- augment(pca, which="var")

pvar <- round(pca$eig$`percentage of variance`[1:2], 1)
coord_pca_12 <- list(
  coord_fixed(),
  labs(x=paste0("PC1 (", pvar[1], "%)"), y=paste0("PC2 (", pvar[2], "%)"))
)

pv12 <- ggplot(pca_v12, aes(alpha=cos2)) +
  geom_segment(aes(x=0, y=0, xend=Dim.1, yend=Dim.2), arrow=arrow(angle=15, length=unit(0.02, "npc"))) +
  # geom_text(aes(x=Dim.1, y=Dim.2, label=label), hjust=0.5, vjust=0.5, size=3) +
  geom_text_repel(aes(x=Dim.1, y=Dim.2, label=label), segment.alpha=0.2, min.segment.length=unit(0.02, "npc"), size=3) +
  scale_alpha(limits=c(0,0.9), range = c(0.4,1)) +
  scale_x_continuous(breaks=0, expand=c(0.05, 0.2)) +
  scale_y_continuous(breaks=0, expand=c(0.05, 0.2)) +
  coord_pca_12

pi12 <- ggplot(pca_i12, aes(Dim.1, Dim.2, alpha=cos2, colour=colour)) +
  geom_point(shape=16, show.legend=FALSE) + geom_text_repel(aes(label=label, size=cos2)) +
  scale_colour_identity() + scale_alpha(limits=c(0,0.9), range = c(0.5,1)) +
  scale_size(limits=c(0,0.9), range=c(0.5,4)) +
  scale_x_continuous(breaks=0) + scale_y_continuous(breaks=0) +
  coord_pca_12

pv12

pi12
```

These plots are read as follows:

- Solutions effective against warming and acidification are effective at global and local scales (arrows are almost overlapping)
- Solutions with a high degree of readiness are those judged to have to most co-benefits, few unintended impacts and good governability.
- Cost effectiveness, lead time until effectiveness, and effectiveness against sea level rise are all badly projected, meaning that solutions are not very differentiated according to these criteria.
- Mitigation of warming, both global and local, is opposed to governability, mitigating other drivers, co-benefits etc. = most solutions cannot score high on criteria in both of these groups. If a solution is effective for warming, it has poor governability and poor effectiveness on other drivers.
- The solutions effective against acidification have very different levels of readiness, co-benefits, etc. (~90ยบ angle)

and

-  The solutions in the green group are effective against warming and acidification (arrows in the second plot point in their direction in the first plot). Hybrids and Albedo are particularly effective for warming-related stuff. Alkalinization global and Renewables are particularly effective for acidification-related stuff. As already explained, in turn, they have poor scores in Global governability, reducing the impact of other drivers, etc. which point in the opposite direction.
- The solutions in the red group are basically the contrary of those in the green group regarding warming and governability, other drivers, co-benefits, readiness. The solutions Vegetation (l), Pollution, Protection have a high degree of readiness, last long, and have good co-benefits.
- The blue group is not very specific. The only pattern is that Cloud is not effective for mitigating acidification and basically scores bad everywhere.

```{r biplot, fig.height=7, fig.width=7}
# # biplot through vegan
# suppressPackageStartupMessages(library("vegan"))
# dd <- data.frame(lapply(d, function(x) {
#   x[is.na(x)] <- mean(x, na.rm=T)
#   return(x)
# }))
# row.names(dd) <- row.names(d)
# 
# pca_v <- rda(dd, scale=F)
# biplot(pca_v, scaling="sites")
```


To examine the solutions and criteria not well represented in dimension 1 and 2, we can examine dimensions 2 and 3:

```{r PCA_and_clust23, fig.height=5, fig.width=6}
# extract objects from PCA
pca_i23 <- augment(pca, dimensions=c(2,3))
# add clusters
pca_i23 <- left_join(pca_i23, groups, by = "label")
# extract variables from PCA
pca_v23 <- augment(pca, which="var", dimensions=c(2,3))

pvar <- round(pca$eig$`percentage of variance`[2:3], 1)
coord_pca_23 <- list(
  coord_fixed(),
  labs(x=paste0("PC2 (", pvar[1], "%)"), y=paste0("PC3 (", pvar[2], "%)"))
)

ggplot(pca_v23, aes(alpha=cos2)) +
  geom_segment(aes(x=0, y=0, xend=Dim.2, yend=Dim.3), arrow=arrow(angle=15, length=unit(0.02, "npc"))) +
  # geom_text(aes(x=Dim.1, y=Dim.2, label=label), hjust=0.5, vjust=0.5, size=3) +
  geom_text_repel(aes(x=Dim.2, y=Dim.3, label=label), segment.alpha=0.2, min.segment.length=unit(0.02, "npc"), size=3) +
  scale_alpha(limits=c(0,0.9)) +
  scale_x_continuous(breaks=0, expand=c(0.05, 0.2)) +
  scale_y_continuous(breaks=0, expand=c(0.05, 0.2)) +
  coord_pca_23

ggplot(pca_i23, aes(Dim.2, Dim.3, alpha=cos2, colour=colour)) +
  geom_point() + geom_text_repel(aes(label=label), size=3) +
  scale_colour_identity() + scale_alpha(limits=c(0,0.9)) +
  scale_x_continuous(breaks=0) + scale_y_continuous(breaks=0) +
  coord_pca_23
```

This does not add much information (as expected since PCs 1 and 2 already capture 62% of the variance). We could still remark that:

- Alkalinization loc is somewhat effective against acidification and not very effective against sea level rise (which seems like it can be expected even by my non-specialist-self ;-) )
- Evolution and Productivity are confirmed to have mostly bad scores in everything.

Hope that helps!

---

## For the paper

### Main text

```{r PCA_paper, fig.width=4.75*2, warning=F, message=F}
paper_theme <- function(base_size=10, ...) {
  theme_linedraw(base_size=base_size, ...) +
  theme(
    # do not waste whitespace
    plot.margin=margin(t=0,r=1,b=0,l=0, unit="mm"),
    # compress legend
    legend.key.size=unit(5, "mm"),
    legend.margin=margin(0,0,0,0, unit="mm"),
    legend.box.margin=margin(0,0,0,0, unit="mm"),
    # the grid in linedraw is too thin at small sizes
    panel.grid.major=element_line(size=0.25),
    # axes labels are useless for PCA
    axis.text=element_blank(),axis.ticks=element_blank()
  ) 
}

# layout figures side by side
library("gridExtra")
p <- grid.arrange(
  pv12 + paper_theme(12) + guides(alpha="none") + scale_y_continuous(breaks=0, expand=c(0.05,0.52)) + annotation_custom(grid::textGrob("A"), xmin=-1.53, xmax=-1.53, ymin=1.7, ymax=1.7),
  pi12 + paper_theme(12) + labs(alpha="Repr.", size="Repr.", y=NULL) + annotation_custom(grid::textGrob("B"), xmin=4.75, xmax=4.75, ymin=4.3, ymax=4.3),
  nrow=1
)
# output at x2 the final size
# NB: font size was 12pt => 6pt at final size
ggsave(p, filename=paste0("fig_pca_", Sys.Date(), ".pdf"), width=4.75*2, height=4.1, units="in")
ggsave(p, filename=paste0("fig_pca_", Sys.Date(), ".png"), width=4.75*2, height=4.1, units="in")
```

*Fig. XX. Principal Components Analysis of the attributes of ocean-based solutions.  
The first plot displays the correlations among attributes. When two arrows point in the same direction, the attributes are correlated (i.e. the scores of most solutions are similar for these two attributes; e.g. both warming-related attributes, co-benefits and readiness). When they point in opposite directions, attributes are anti-correlated (e.g. warming and governability). When they are perpendicular, attributes are uncorrelated (e.g. acidification-related attributes and readiness).  
The second plot displays the positions of solutions in this PCA space. Solutions on the right have high scores in the attributes that point to the right and low scores in the attributes that point to the left; a similar reasoning can be made for any direction in this space. Solutions are clustered into three groups, based on their position in the PCA space, and coloured accordingly.  
The first two principal components explain 64% of the variance in the attributes of ocean-based solutions. Attributes or solutions that are not well represented in this space are made semi-transparent (representativity = "Repr." varies between 0 and 1).  
The scores of attributes were averaged across ecosystems and ecosystem services.*

The first principal component is mostly driven by governability, readiness, co-benefits and, to a lesser extent, the duration of the effect and the lack of unintended effects (Fig. Xa). Therefore, it can be considered to represent "feasibility". By definition of the PCA, solutions differ most in these feasibility attributes (>40% of the variance). In particular, most solutions effective to reduce warming and its impacts have low feasibility. Along the second principal component most arrows point up, so it could be broadly interpreted as "efficacy". A number of attributes (effectiveness to moderate sea level rise, lead time until full effectiveness and cost effectiveness) are not immediately useful to discriminate solutions.

Three groups of solutions emerge (Fig. Xb). Measures in green (renewable energy, Alkalinization addition at global scale, increased albedo and hybrid measures) are effective to reduce warming, acidification, and their impacts but, as explained above, score low in feasibility. In contrast, measures in red have low effectiveness to reduce warming and its impact and moderate effectiveness to reduce ocean acidification and its impact. They are, however, technically ready, have significant co-benefits, few dis-benefits and can also help reduce the impact of other drivers of climate change. This group comprises almost all local measures. Finally, solutions in the blue group score averagely in all of the attributes assessed. It comprises Alkalinization addition implemented at local scale, evolution, productivity and marine cloud brightening, the later faring particularly poorly for moderation of ocean acidification.

### Methods

To get a synthetic view of the attributes of the various ocean-based solutions, they were summarised through a principal component analysis (PCA) and grouped through hierarchical ascending clustering (HAC).

The Euclidean distance between the raw scores of all solutions for all attributes was computed. PCA usually uses scaled values (centred on the mean, divided by the variance). Here, using the raw scores meant that (i) the value that we, as humans, place on an increase of 1 in the score is the same for all attributes and at any point in the scoring scale (e.g. a difference between 1 and 2 in readiness is as important as a difference between 4 and 5 in the effectiveness to moderate warming); (ii) attributes whose scores vary little among solutions have low weight in the analysis. This Euclidian distance matrix was then used to compute the PCA space. The quality of the representation of the attributes and solutions on each principal component was quantified by their squared cosine. The squared cosines for principal components 1 and 2 used in Fig. X were summed to get the global representativity in the plane they define ("Repr." in the legend).

The relevance of the principal components to discriminate solutions was judged from their associated eigenvalues, which were compared to the mean eigenvalue (Kaiser-Guttman criterion) and a broken-stick model. Four principal components were retained and used for clustering. The clustering algorithm used Euclidean distance and Ward's aggregation method, in order to highlight synoptic groups. The number of groups was defined based on the aspect of the resulting tree, which unambiguously separated three main groups before a succession of short branches in each group.

The analysis was performed on the full dataset and on a reduced dataset in which attributes were averaged per ecosystem and ecosystem services. The results were very similar and only the simpler version was kept for clarity.

All analyses were performed in R 3.4 with packages FactoMineR 1.36 for PCA, tidyverse 1.1.1 for data manipulation, and ggplot2 2.2.1 for graphics.

```{r}
sessionInfo()
```
